{
 "metadata": {
  "name": "",
  "signature": "sha256:7e85cf665305c2d1aa0b22334f5a2585dba0dd46b80d608637d1e2ea15e1c2de"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../image_featurization_real/data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/JeffreyTang/Desktop/zipfian/spring2015/image_featurization_real/data\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import scale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('murder_rate.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = pd.read_csv('buy_or_not.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>percent_below_5000</th>\n",
        "      <th>percent_unemployed</th>\n",
        "      <th>murder_per_million</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 16.5</td>\n",
        "      <td> 6.2</td>\n",
        "      <td> 11.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 20.5</td>\n",
        "      <td> 6.4</td>\n",
        "      <td> 13.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 26.3</td>\n",
        "      <td> 9.3</td>\n",
        "      <td> 40.7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 16.5</td>\n",
        "      <td> 5.3</td>\n",
        "      <td>  5.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 19.2</td>\n",
        "      <td> 7.3</td>\n",
        "      <td> 24.8</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "   percent_below_5000  percent_unemployed  murder_per_million\n",
        "0                16.5                 6.2                11.2\n",
        "1                20.5                 6.4                13.4\n",
        "2                26.3                 9.3                40.7\n",
        "3                16.5                 5.3                 5.3\n",
        "4                19.2                 7.3                24.8"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "(673, 3)"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = df2.pop('buy_or_not').values.astype(np.int32)\n",
      "x = scale(df2.values).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:145: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n",
        "  Xr -= mean_\n",
        "/usr/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:158: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n",
        "  Xr -= mean_1\n",
        "/usr/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:160: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n",
        "  Xr /= std_\n",
        "/usr/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:174: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n",
        "  Xr -= mean_2\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagne import layers\n",
      "from lasagne.nonlinearities import  softmax, rectify, sigmoid, linear\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet\n",
      "import theano"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NeuralNet(layers=[('input', layers.InputLayer),\n",
      "#                        ('hidden', layers.DenseLayer),                       \n",
      "                       ('output', layers.DenseLayer),\n",
      "               ],\n",
      "\n",
      "               # Input Layer\n",
      "               input_shape=(None, x.shape[1]),\n",
      "\n",
      "             # Hidden Layer\n",
      "#               hidden_num_units=20,\n",
      "#               hidden_nonlinearity=sigmoid,\n",
      "         \n",
      "              # Output Layer\n",
      "              output_num_units=2,\n",
      "              output_nonlinearity=softmax,\n",
      "\n",
      "              # Optimization\n",
      "              update=nesterov_momentum,\n",
      "              update_learning_rate=0.05,\n",
      "              update_momentum=0.7,\n",
      "              max_epochs=50,\n",
      "\n",
      "              # Others\n",
      "              eval_size=0.2,\n",
      "              regression=False,\n",
      "              verbose=1,\n",
      "         )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn.fit(x, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input             \t(None, 2)           \tproduces       2 outputs\n",
        "  output            \t(None, 2)           \tproduces       2 outputs\n",
        "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
        "-------  ------------  ------------  -----------  -----------  -----\n",
        "      1       \u001b[94m0.71303\u001b[0m       \u001b[32m0.65861\u001b[0m      1.08263      0.66964  0.00s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "      2       \u001b[94m0.60545\u001b[0m       \u001b[32m0.52684\u001b[0m      1.14921      0.90625  0.00s\n",
        "      3       \u001b[94m0.53498\u001b[0m       \u001b[32m0.44769\u001b[0m      1.19497      0.90234  0.00s\n",
        "      4       \u001b[94m0.49262\u001b[0m       \u001b[32m0.39815\u001b[0m      1.23726      0.90234  0.00s\n",
        "      5       \u001b[94m0.46370\u001b[0m       \u001b[32m0.36392\u001b[0m      1.27417      0.90234  0.00s\n",
        "      6       \u001b[94m0.44135\u001b[0m       \u001b[32m0.33812\u001b[0m      1.30528      0.90234  0.00s\n",
        "      7       \u001b[94m0.42276\u001b[0m       \u001b[32m0.31745\u001b[0m      1.33173      0.90234  0.00s\n",
        "      8       \u001b[94m0.40674\u001b[0m       \u001b[32m0.30020\u001b[0m      1.35487      0.90234  0.00s\n",
        "      9       \u001b[94m0.39268\u001b[0m       \u001b[32m0.28542\u001b[0m      1.37581      0.90234  0.00s\n",
        "     10       \u001b[94m0.38025\u001b[0m       \u001b[32m0.27252\u001b[0m      1.39534      0.90234  0.00s\n",
        "     11       \u001b[94m0.36923\u001b[0m       \u001b[32m0.26112\u001b[0m      1.41399      0.90234  0.00s\n",
        "     12       \u001b[94m0.35941\u001b[0m       \u001b[32m0.25097\u001b[0m      1.43211      0.90234  0.00s\n",
        "     13       \u001b[94m0.35067\u001b[0m       \u001b[32m0.24186\u001b[0m      1.44989      0.90234  0.00s\n",
        "     14       \u001b[94m0.34287\u001b[0m       \u001b[32m0.23365\u001b[0m      1.46742      0.90234  0.00s\n",
        "     15       \u001b[94m0.33588\u001b[0m       \u001b[32m0.22622\u001b[0m      1.48476      0.91016  0.00s\n",
        "     16       \u001b[94m0.32963\u001b[0m       \u001b[32m0.21947\u001b[0m      1.50192      0.96484  0.00s\n",
        "     17       \u001b[94m0.32401\u001b[0m       \u001b[32m0.21332\u001b[0m      1.51888      0.96484  0.00s\n",
        "     18       \u001b[94m0.31895\u001b[0m       \u001b[32m0.20770\u001b[0m      1.53564      0.96484  0.00s\n",
        "     19       \u001b[94m0.31439\u001b[0m       \u001b[32m0.20255\u001b[0m      1.55216      0.96484  0.00s\n",
        "     20       \u001b[94m0.31027\u001b[0m       \u001b[32m0.19783\u001b[0m      1.56842      0.96484  0.00s\n",
        "     21       \u001b[94m0.30654\u001b[0m       \u001b[32m0.19348\u001b[0m      1.58440      0.96875  0.00s\n",
        "     22       \u001b[94m0.30316\u001b[0m       \u001b[32m0.18947\u001b[0m      1.60008      0.96875  0.00s\n",
        "     23       \u001b[94m0.30008\u001b[0m       \u001b[32m0.18576\u001b[0m      1.61545      0.96875  0.00s\n",
        "     24       \u001b[94m0.29728\u001b[0m       \u001b[32m0.18233\u001b[0m      1.63049      0.96875  0.00s\n",
        "     25       \u001b[94m0.29473\u001b[0m       \u001b[32m0.17914\u001b[0m      1.64520      0.96875  0.00s\n",
        "     26       \u001b[94m0.29239\u001b[0m       \u001b[32m0.17619\u001b[0m      1.65956      0.96875  0.00s\n",
        "     27       \u001b[94m0.29026\u001b[0m       \u001b[32m0.17343\u001b[0m      1.67358      0.96875  0.00s\n",
        "     28       \u001b[94m0.28830\u001b[0m       \u001b[32m0.17087\u001b[0m      1.68725      0.96875  0.00s\n",
        "     29       \u001b[94m0.28650\u001b[0m       \u001b[32m0.16847\u001b[0m      1.70057      0.96875  0.01s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     30       \u001b[94m0.28484\u001b[0m       \u001b[32m0.16623\u001b[0m      1.71354      0.96875  0.00s\n",
        "     31       \u001b[94m0.28332\u001b[0m       \u001b[32m0.16413\u001b[0m      1.72617      0.96875  0.00s\n",
        "     32       \u001b[94m0.28191\u001b[0m       \u001b[32m0.16216\u001b[0m      1.73846      0.96875  0.00s\n",
        "     33       \u001b[94m0.28061\u001b[0m       \u001b[32m0.16031\u001b[0m      1.75041      0.96875  0.00s\n",
        "     34       \u001b[94m0.27941\u001b[0m       \u001b[32m0.15857\u001b[0m      1.76204      0.96875  0.00s\n",
        "     35       \u001b[94m0.27830\u001b[0m       \u001b[32m0.15694\u001b[0m      1.77334      0.96875  0.00s\n",
        "     36       \u001b[94m0.27727\u001b[0m       \u001b[32m0.15539\u001b[0m      1.78432      0.96875  0.00s\n",
        "     37       \u001b[94m0.27632\u001b[0m       \u001b[32m0.15394\u001b[0m      1.79500      0.96875  0.00s\n",
        "     38       \u001b[94m0.27543\u001b[0m       \u001b[32m0.15256\u001b[0m      1.80538      0.96875  0.00s\n",
        "     39       \u001b[94m0.27461\u001b[0m       \u001b[32m0.15126\u001b[0m      1.81546      0.96875  0.00s\n",
        "     40       \u001b[94m0.27384\u001b[0m       \u001b[32m0.15003\u001b[0m      1.82525      0.96875  0.00s\n",
        "     41       \u001b[94m0.27313\u001b[0m       \u001b[32m0.14886\u001b[0m      1.83476      0.96875  0.00s\n",
        "     42       \u001b[94m0.27247\u001b[0m       \u001b[32m0.14776\u001b[0m      1.84400      0.96875  0.00s\n",
        "     43       \u001b[94m0.27185\u001b[0m       \u001b[32m0.14671\u001b[0m      1.85298      0.96875  0.00s\n",
        "     44       \u001b[94m0.27127\u001b[0m       \u001b[32m0.14571\u001b[0m      1.86170      0.96875  0.00s\n",
        "     45       \u001b[94m0.27073\u001b[0m       \u001b[32m0.14476\u001b[0m      1.87017      0.96875  0.00s\n",
        "     46       \u001b[94m0.27022\u001b[0m       \u001b[32m0.14386\u001b[0m      1.87840      0.96875  0.00s\n",
        "     47       \u001b[94m0.26975\u001b[0m       \u001b[32m0.14300\u001b[0m      1.88640      0.96875  0.00s\n",
        "     48       \u001b[94m0.26930\u001b[0m       \u001b[32m0.14218\u001b[0m      1.89416      0.96875  0.00s\n",
        "     49       \u001b[94m0.26889\u001b[0m       \u001b[32m0.14139\u001b[0m      1.90171      0.96875  0.00s\n",
        "     50       \u001b[94m0.26850\u001b[0m       \u001b[32m0.14065\u001b[0m      1.90904      0.96875  0.00s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "NeuralNet(X_tensor_type=<function matrix at 0x10be1d500>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x105c57dd0>,\n",
        "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x105c4c0d0>,\n",
        "     custom_score=None, eval_size=0.2, input_shape=(None, 2),\n",
        "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
        "     loss=None, max_epochs=50, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function categorical_crossentropy at 0x10ba4bf50>,\n",
        "     on_epoch_finished=[<nolearn.lasagne.util.PrintLog instance at 0x10f7cdab8>],\n",
        "     on_training_finished=[],\n",
        "     output_nonlinearity=<function softmax at 0x10bcdf488>,\n",
        "     output_num_units=2, regression=False,\n",
        "     update=<function nesterov_momentum at 0x10c67e2a8>,\n",
        "     update_learning_rate=0.05, update_momentum=0.7,\n",
        "     use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(int32, vector))"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_layer, input_layer = nn.get_all_layers()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w, b = output_layer.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([[-1.0083358 ,  1.53789784],\n",
        "       [-0.02159764,  0.05729499]])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = nn.train_test_split(x, y, 0.2)\n",
      "logit = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit.fit(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit.score(x_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.91851851851851851"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>percent_below_5000</th>\n",
        "      <th>percent_unemployed</th>\n",
        "      <th>murder_per_million</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 16.5</td>\n",
        "      <td> 6.2</td>\n",
        "      <td> 11.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 20.5</td>\n",
        "      <td> 6.4</td>\n",
        "      <td> 13.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 26.3</td>\n",
        "      <td> 9.3</td>\n",
        "      <td> 40.7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 16.5</td>\n",
        "      <td> 5.3</td>\n",
        "      <td>  5.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 19.2</td>\n",
        "      <td> 7.3</td>\n",
        "      <td> 24.8</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "   percent_below_5000  percent_unemployed  murder_per_million\n",
        "0                16.5                 6.2                11.2\n",
        "1                20.5                 6.4                13.4\n",
        "2                26.3                 9.3                40.7\n",
        "3                16.5                 5.3                 5.3\n",
        "4                19.2                 7.3                24.8"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = df.pop('murder_per_million').values.astype(np.float32)[:, np.newaxis]\n",
      "x = scale(df.values.astype(np.float32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "(20, 1)"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn_regression = NeuralNet(layers=[('input', layers.InputLayer),\n",
      "#                                   ('hidden', layers.DenseLayer),\n",
      "                                ('output', layers.DenseLayer)\n",
      "                            ],\n",
      "\n",
      "               # Input Layer\n",
      "               input_shape=(None, x.shape[1]),\n",
      "\n",
      "              # hidden Layer\n",
      "#               hidden_num_units=x.shape[1],\n",
      "#               hidden_nonlinearity=rectify,\n",
      "\n",
      "              # Output Layer\n",
      "              output_num_units=1,\n",
      "              output_nonlinearity=linear,\n",
      "\n",
      "              # Optimization\n",
      "              update=nesterov_momentum,\n",
      "              update_learning_rate=0.05,\n",
      "              update_momentum=0.7,\n",
      "              max_epochs=100,\n",
      "\n",
      "              # Others\n",
      "              eval_size=0.2,\n",
      "              regression=True,\n",
      "              verbose=1,\n",
      "         )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn_regression.fit(x, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input             \t(None, 2)           \tproduces       2 outputs\n",
        "  output            \t(None, 1)           \tproduces       1 outputs\n",
        "  epoch    train loss    valid loss    train/val  dur\n",
        "-------  ------------  ------------  -----------  -----\n",
        "      1     \u001b[94m521.05512\u001b[0m     \u001b[32m320.85244\u001b[0m      1.62397  0.00s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "      2     \u001b[94m357.39413\u001b[0m     \u001b[32m172.68499\u001b[0m      2.06963  0.00s\n",
        "      3     \u001b[94m214.43608\u001b[0m      \u001b[32m76.64033\u001b[0m      2.79795  0.00s\n",
        "      4     \u001b[94m114.85988\u001b[0m      \u001b[32m28.14097\u001b[0m      4.08159  0.00s\n",
        "      5      \u001b[94m57.30891\u001b[0m      \u001b[32m11.84989\u001b[0m      4.83624  0.00s\n",
        "      6      \u001b[94m30.08531\u001b[0m      12.53339      2.40041  0.00s\n",
        "      7      \u001b[94m20.46284\u001b[0m      19.47440      1.05076  0.00s\n",
        "      8      \u001b[94m18.91596\u001b[0m      26.80187      0.70577  0.00s\n",
        "      9      19.86629      32.14062      0.61811  0.00s\n",
        "     10      20.79682      35.07367      0.59295  0.00s\n",
        "     11      21.00614      36.02296      0.58313  0.00s\n",
        "     12      20.60946      35.62132      0.57857  0.00s\n",
        "     13      19.93747      34.43845      0.57893  0.00s\n",
        "     14      19.26365      32.90181      0.58549  0.00s\n",
        "     15      \u001b[94m18.73238\u001b[0m      31.30113      0.59846  0.00s\n",
        "     16      \u001b[94m18.37988\u001b[0m      29.81720      0.61642  0.00s\n",
        "     17      \u001b[94m18.18049\u001b[0m      28.55120      0.63677  0.00s\n",
        "     18      \u001b[94m18.08665\u001b[0m      27.54791      0.65655  0.00s\n",
        "     19      \u001b[94m18.05311\u001b[0m      26.81312      0.67329  0.00s\n",
        "     20      \u001b[94m18.04713\u001b[0m      26.32666      0.68551  0.00s\n",
        "     21      18.04956      26.05257      0.69281  0.00s\n",
        "     22      18.05165      25.94708      0.69571  0.00s\n",
        "     23      18.05098      25.96480      0.69521  0.00s\n",
        "     24      18.04808      26.06334      0.69247  0.00s\n",
        "     25      \u001b[94m18.04429\u001b[0m      26.20641      0.68855  0.00s\n",
        "     26      \u001b[94m18.04071\u001b[0m      26.36538      0.68426  0.00s\n",
        "     27      \u001b[94m18.03790\u001b[0m      26.51975      0.68017  0.00s\n",
        "     28      \u001b[94m18.03597\u001b[0m      26.65657      0.67660  0.00s\n",
        "     29      \u001b[94m18.03477\u001b[0m      26.76925      0.67371  0.00s\n",
        "     30      \u001b[94m18.03407\u001b[0m      26.85609      0.67151  0.00s\n",
        "     31      \u001b[94m18.03365\u001b[0m      26.91871      0.66993  0.00s\n",
        "     32      \u001b[94m18.03338\u001b[0m      26.96070      0.66888  0.00s\n",
        "     33      \u001b[94m18.03317\u001b[0m      26.98649      0.66823  0.00s\n",
        "     34      \u001b[94m18.03298\u001b[0m      27.00058      0.66787  0.00s\n",
        "     35      \u001b[94m18.03281\u001b[0m      27.00696      0.66771  0.00s\n",
        "     36      \u001b[94m18.03265\u001b[0m      27.00891      0.66766  0.00s\n",
        "     37      \u001b[94m18.03251\u001b[0m      27.00886      0.66765  0.00s\n",
        "     38      \u001b[94m18.03240\u001b[0m      27.00848      0.66766  0.00s\n",
        "     39      \u001b[94m18.03230\u001b[0m      27.00875      0.66765  0.00s\n",
        "     40      \u001b[94m18.03222\u001b[0m      27.01015      0.66761  0.00s\n",
        "     41      \u001b[94m18.03216\u001b[0m      27.01279      0.66754  0.00s\n",
        "     42      \u001b[94m18.03210\u001b[0m      27.01655      0.66745  0.00s\n",
        "     43      \u001b[94m18.03206\u001b[0m      27.02117      0.66733  0.00s\n",
        "     44      \u001b[94m18.03202\u001b[0m      27.02636      0.66720  0.00s\n",
        "     45      \u001b[94m18.03199\u001b[0m      27.03183      0.66706  0.00s\n",
        "     46      \u001b[94m18.03196\u001b[0m      27.03733      0.66693  0.00s\n",
        "     47      \u001b[94m18.03194\u001b[0m      27.04267      0.66680  0.00s\n",
        "     48      \u001b[94m18.03192\u001b[0m      27.04772      0.66667  0.00s\n",
        "     49      \u001b[94m18.03190\u001b[0m      27.05240      0.66655  0.00s\n",
        "     50      \u001b[94m18.03189\u001b[0m      27.05667      0.66645  0.00s\n",
        "     51      \u001b[94m18.03187\u001b[0m      27.06053      0.66635  0.00s\n",
        "     52      \u001b[94m18.03186\u001b[0m      27.06399      0.66627  0.00s\n",
        "     53      \u001b[94m18.03186\u001b[0m      27.06709      0.66619  0.00s\n",
        "     54      \u001b[94m18.03185\u001b[0m      27.06986      0.66612  0.00s\n",
        "     55      \u001b[94m18.03184\u001b[0m      27.07234      0.66606  0.00s\n",
        "     56      \u001b[94m18.03184\u001b[0m      27.07458      0.66601  0.00s\n",
        "     57      \u001b[94m18.03183\u001b[0m      27.07661      0.66596  0.00s\n",
        "     58      \u001b[94m18.03183\u001b[0m      27.07844      0.66591  0.00s\n",
        "     59      \u001b[94m18.03183\u001b[0m      27.08012      0.66587  0.00s\n",
        "     60      \u001b[94m18.03182\u001b[0m      27.08166      0.66583  0.00s\n",
        "     61      \u001b[94m18.03182\u001b[0m      27.08307      0.66580  0.00s\n",
        "     62      \u001b[94m18.03182\u001b[0m      27.08438      0.66576  0.00s\n",
        "     63      \u001b[94m18.03182\u001b[0m      27.08558      0.66574  0.00s\n",
        "     64      \u001b[94m18.03182\u001b[0m      27.08669      0.66571  0.00s\n",
        "     65      \u001b[94m18.03182\u001b[0m      27.08771      0.66568  0.00s\n",
        "     66      \u001b[94m18.03182\u001b[0m      27.08866      0.66566  0.00s\n",
        "     67      \u001b[94m18.03181\u001b[0m      27.08953      0.66564  0.00s\n",
        "     68      \u001b[94m18.03181\u001b[0m      27.09034      0.66562  0.00s\n",
        "     69      \u001b[94m18.03181\u001b[0m      27.09109      0.66560  0.00s\n",
        "     70      \u001b[94m18.03181\u001b[0m      27.09177      0.66558  0.00s\n",
        "     71      \u001b[94m18.03181\u001b[0m      27.09240      0.66557  0.00s\n",
        "     72      \u001b[94m18.03181\u001b[0m      27.09298      0.66555  0.00s\n",
        "     73      \u001b[94m18.03181\u001b[0m      27.09352      0.66554  0.00s\n",
        "     74      \u001b[94m18.03181\u001b[0m      27.09401      0.66553  0.00s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     75      \u001b[94m18.03181\u001b[0m      27.09446      0.66552  0.00s\n",
        "     76      \u001b[94m18.03181\u001b[0m      27.09487      0.66551  0.00s\n",
        "     77      \u001b[94m18.03181\u001b[0m      27.09525      0.66550  0.00s\n",
        "     78      \u001b[94m18.03181\u001b[0m      27.09560      0.66549  0.00s\n",
        "     79      \u001b[94m18.03181\u001b[0m      27.09593      0.66548  0.00s\n",
        "     80      \u001b[94m18.03181\u001b[0m      27.09622      0.66547  0.00s\n",
        "     81      \u001b[94m18.03181\u001b[0m      27.09649      0.66547  0.00s\n",
        "     82      \u001b[94m18.03181\u001b[0m      27.09674      0.66546  0.00s\n",
        "     83      \u001b[94m18.03181\u001b[0m      27.09697      0.66545  0.00s\n",
        "     84      \u001b[94m18.03181\u001b[0m      27.09718      0.66545  0.00s\n",
        "     85      \u001b[94m18.03181\u001b[0m      27.09738      0.66544  0.00s\n",
        "     86      \u001b[94m18.03181\u001b[0m      27.09756      0.66544  0.00s\n",
        "     87      \u001b[94m18.03181\u001b[0m      27.09772      0.66544  0.00s\n",
        "     88      \u001b[94m18.03181\u001b[0m      27.09787      0.66543  0.00s\n",
        "     89      \u001b[94m18.03181\u001b[0m      27.09801      0.66543  0.00s\n",
        "     90      \u001b[94m18.03181\u001b[0m      27.09814      0.66543  0.00s\n",
        "     91      \u001b[94m18.03181\u001b[0m      27.09825      0.66542  0.00s\n",
        "     92      \u001b[94m18.03181\u001b[0m      27.09836      0.66542  0.00s\n",
        "     93      \u001b[94m18.03181\u001b[0m      27.09846      0.66542  0.00s\n",
        "     94      \u001b[94m18.03181\u001b[0m      27.09855      0.66542  0.00s\n",
        "     95      \u001b[94m18.03181\u001b[0m      27.09864      0.66541  0.00s\n",
        "     96      \u001b[94m18.03181\u001b[0m      27.09871      0.66541  0.00s\n",
        "     97      \u001b[94m18.03181\u001b[0m      27.09879      0.66541  0.00s\n",
        "     98      \u001b[94m18.03181\u001b[0m      27.09885      0.66541  0.00s\n",
        "     99      \u001b[94m18.03181\u001b[0m      27.09891      0.66541  0.00s\n",
        "    100      \u001b[94m18.03181\u001b[0m      27.09897      0.66541  0.00s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "NeuralNet(X_tensor_type=<function matrix at 0x10be1d500>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x105c57dd0>,\n",
        "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x105c4c0d0>,\n",
        "     custom_score=None, eval_size=0.2, input_shape=(None, 2),\n",
        "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
        "     loss=None, max_epochs=100, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function mse at 0x10c6732a8>,\n",
        "     on_epoch_finished=[<nolearn.lasagne.util.PrintLog instance at 0x10dfbb830>],\n",
        "     on_training_finished=[],\n",
        "     output_nonlinearity=<function linear at 0x10bce4230>,\n",
        "     output_num_units=1, regression=True,\n",
        "     update=<function nesterov_momentum at 0x10c67e2a8>,\n",
        "     update_learning_rate=0.05, update_momentum=0.7,\n",
        "     use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(float32, matrix))"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn_regression.eval_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "0.2"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LinearRegression()\n",
      "x_train, x_test, y_train, y_test = nn_regression.train_test_split(x, y, 0.2)\n",
      "lr.fit(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = lr.predict(x_test)\n",
      "mean_squared_error(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "27.099596257622032"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w, b = nn_regression.get_all_params()\n",
      "w.get_value()\n",
      "b.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "array([[ 4.1893289 ],\n",
        "       [ 3.93231326]])"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "array([ 21.26342174])"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "array([[ 4.1896472 ,  3.93199301]])"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "array([ 21.2634398])"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.random()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "0.22767579702846574"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "def grad(x):\n",
      "    return 2 * x + 2\n",
      "\n",
      "def solver(iterations=1000, tol=0.0001, learning_rate=0.05):\n",
      "    x = random.random()\n",
      "    prev_x = None\n",
      "    for _ in range(iterations):\n",
      "        prev_x = x\n",
      "        x -= learning_rate * grad(x)\n",
      "        if abs(prev_x - x) <= tol:\n",
      "            return x\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "solver()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "-0.9991710801673533"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.optimize as sco\n",
      "\n",
      "def f(x):\n",
      "    return x**2 + 2 * x\n",
      "\n",
      "print sco.fmin_tnc(f, 0.3, approx_grad=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(array([-1.00000001]), 13, 0)\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f(1.29677804e-06)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 144,
       "text": [
        "2.0000000000016818"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f(0.00032092)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 148,
       "text": [
        "2.000000103022698"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}